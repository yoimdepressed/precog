{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff46c2a9",
   "metadata": {},
   "source": [
    "# Task 1: The Fingerprint\n",
    "## Proving Classes Are Mathematically Distinct\n",
    "\n",
    "Before training ML models, we must prove these 3 classes have measurably different linguistic properties.\n",
    "\n",
    "**Goal:** Perform 6 analyses to show Human, AI Vanilla, and AI Styled texts are statistically distinguishable.\n",
    "\n",
    "---\n",
    "\n",
    "## Analyses:\n",
    "1. **Type-Token Ratio (TTR)** - Vocabulary diversity\n",
    "2. **Hapax Legomena** - Rare words (appearing once)\n",
    "3. **POS Distribution** - Adjective-to-Noun ratio\n",
    "4. **Sentence Length Variance** - Structural rhythm\n",
    "5. **Punctuation Density** - Stylistic markers\n",
    "6. **Flesch-Kincaid Grade Level** - Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94f802",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c10f6",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated path for Twain + Austen dataset\n",
    "DATA_DIR = Path('../TASK0/data/dataset/twain_austen')\n",
    "\n",
    "# Load Class 1 (Human - JSONL format)\n",
    "class1_texts = []\n",
    "with open(DATA_DIR / 'class1_human.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            class1_texts.append(json.loads(line)['text'])\n",
    "\n",
    "# Load Class 2 (AI Vanilla - TXT format, 1 para per line)\n",
    "with open(DATA_DIR / 'class2.txt', 'r', encoding='utf-8') as f:\n",
    "    class2_texts = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Load Class 3 (AI Styled - TXT format, 1 para per line)\n",
    "with open(DATA_DIR / 'class3.txt', 'r', encoding='utf-8') as f:\n",
    "    class3_texts = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"‚úÖ Loaded Twain + Austen Dataset:\")\n",
    "print(f\"  Class 1 (Human): {len(class1_texts)} paragraphs\")\n",
    "print(f\"  Class 2 (AI Vanilla): {len(class2_texts)} paragraphs\")\n",
    "print(f\"  Class 3 (AI Styled): {len(class3_texts)} paragraphs\")\n",
    "print(f\"\\nExpected:\")\n",
    "print(f\"  Class 1: ~470-500 human paragraphs\")\n",
    "print(f\"  Class 2: ~470-500 AI Vanilla paragraphs\")\n",
    "print(f\"  Class 3: ~470-500 AI Styled paragraphs (Twain + Austen)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95f09c",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Type-Token Ratio (TTR)\n",
    "\n",
    "Measures vocabulary diversity: unique words / total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aefba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ttr(text):\n",
    "    \"\"\"Type-Token Ratio: vocabulary diversity\"\"\"\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    if len(tokens) == 0:\n",
    "        return 0\n",
    "    unique_tokens = set(tokens)\n",
    "    return len(unique_tokens) / len(tokens)\n",
    "\n",
    "# Calculate for all classes\n",
    "class1_ttr = [calculate_ttr(text) for text in class1_texts]\n",
    "class2_ttr = [calculate_ttr(text) for text in class2_texts]\n",
    "class3_ttr = [calculate_ttr(text) for text in class3_texts]\n",
    "\n",
    "print(f\"Average TTR:\")\n",
    "print(f\"  Human (Class 1): {np.mean(class1_ttr):.3f}\")\n",
    "print(f\"  AI Vanilla (Class 2): {np.mean(class2_ttr):.3f}\")\n",
    "print(f\"  AI Styled (Class 3): {np.mean(class3_ttr):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484819ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "data = pd.DataFrame({\n",
    "    'TTR': class1_ttr + class2_ttr + class3_ttr,\n",
    "    'Class': ['Human']*len(class1_ttr) + ['AI_Vanilla']*len(class2_ttr) + ['AI_Styled']*len(class3_ttr)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x='Class', y='TTR', palette='Set2')\n",
    "plt.title('Type-Token Ratio by Class', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('TTR (Vocabulary Diversity)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6271655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "t_stat, p_value = stats.ttest_ind(class1_ttr, class2_ttr)\n",
    "\n",
    "print(f\"\\nT-test (Human vs AI Vanilla):\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"  ‚úÖ Statistically significant difference (p < 0.05)\")\n",
    "    diff = abs(np.mean(class1_ttr) - np.mean(class2_ttr))\n",
    "    print(f\"  Difference: {diff:.3f}\")\n",
    "else:\n",
    "    print(f\"  ‚ùå No significant difference (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a2f42",
   "metadata": {},
   "source": [
    "### TTR Summary\n",
    "\n",
    "**Results:**\n",
    "- Human (Twain + Austen): **0.674 TTR** (lower)\n",
    "- AI Vanilla: **0.710 TTR** (higher)\n",
    "- AI Styled: **0.700 TTR** (middle)\n",
    "\n",
    "**‚ö†Ô∏è LENGTH BIAS DETECTED!**\n",
    "\n",
    "**Paragraph lengths:**\n",
    "- Human: **134 words** average\n",
    "- AI: **90-97 words** average  \n",
    "- **Difference: 37-44 words** (HUGE!)\n",
    "\n",
    "**Why this creates bias:**\n",
    "- Longer texts ‚Üí more word repetition ‚Üí **lower TTR**\n",
    "- Shorter texts ‚Üí less repetition ‚Üí **higher TTR**\n",
    "- This is a **mathematical artifact** from text length, not pure style\n",
    "\n",
    "**Statistical Significance:**\n",
    "- p < 0.000001 (extremely significant)\n",
    "- Difference: 0.036 (consistent and measurable)\n",
    "- ‚úÖ **Still valid for classification** (models learn length + style together)\n",
    "\n",
    "**Verdict:** ‚ö†Ô∏è **TTR is CONFOUNDED by length bias**\n",
    "- Can't interpret as \"AI has richer vocabulary\"\n",
    "- Actually means \"AI writes shorter paragraphs\"\n",
    "- Still useful as a feature, just not interpretable as pure style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fff315",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Hapax Legomena\n",
    "\n",
    "Words that appear exactly once in a text (rare/unique vocabulary)\n",
    "\n",
    "**Example:** In \"the cat sat on the mat\", hapax = {cat, sat, on, mat} (4 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hapax_ratio(text):\n",
    "    \"\"\"Ratio of words appearing exactly once\"\"\"\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    if len(tokens) == 0:\n",
    "        return 0\n",
    "    word_counts = Counter(tokens)\n",
    "    hapax_count = sum(1 for count in word_counts.values() if count == 1)\n",
    "    return hapax_count / len(tokens)\n",
    "\n",
    "# Calculate for all classes\n",
    "class1_hapax = [calculate_hapax_ratio(text) for text in class1_texts]\n",
    "class2_hapax = [calculate_hapax_ratio(text) for text in class2_texts]\n",
    "class3_hapax = [calculate_hapax_ratio(text) for text in class3_texts]\n",
    "\n",
    "print(f\"Average Hapax Ratio:\")\n",
    "print(f\"  Human (Class 1): {np.mean(class1_hapax):.3f}\")\n",
    "print(f\"  AI Vanilla (Class 2): {np.mean(class2_hapax):.3f}\")\n",
    "print(f\"  AI Styled (Class 3): {np.mean(class3_hapax):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "data = pd.DataFrame({\n",
    "    'Hapax_Ratio': class1_hapax + class2_hapax + class3_hapax,\n",
    "    'Class': ['Human']*len(class1_hapax) + ['AI_Vanilla']*len(class2_hapax) + ['AI_Styled']*len(class3_hapax)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x='Class', y='Hapax_Ratio', palette='Set2')\n",
    "plt.title('Hapax Legomena Ratio by Class', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Hapax Ratio (Rare Words)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae38e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "t_stat, p_value = stats.ttest_ind(class1_hapax, class2_hapax)\n",
    "\n",
    "print(f\"\\nT-test (Human vs AI Vanilla):\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"  ‚úÖ Statistically significant difference (p < 0.05)\")\n",
    "    diff = abs(np.mean(class1_hapax) - np.mean(class2_hapax))\n",
    "    print(f\"  Difference: {diff:.3f}\")\n",
    "else:\n",
    "    print(f\"  ‚ùå No significant difference (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22ed33",
   "metadata": {},
   "source": [
    "### Hapax Summary\n",
    "\n",
    "**Results:**\n",
    "- Human (Twain + Austen): **0.524** (lower)\n",
    "- AI Vanilla: **0.585** (higher)  \n",
    "- AI Styled: **0.571** (middle)\n",
    "\n",
    "**‚ö†Ô∏è LENGTH BIAS DETECTED!**\n",
    "\n",
    "**Paragraph lengths:**\n",
    "- Human: **134 words** average\n",
    "- AI: **90-97 words** average\n",
    "- **Difference: 37-44 words** (HUGE!)\n",
    "\n",
    "**Why this matters:**\n",
    "Longer texts naturally have **lower Hapax ratios** because:\n",
    "1. More words = more opportunities to repeat common words\n",
    "2. The longer you write, the more \"the,\" \"a,\" \"is,\" \"said\" appear multiple times\n",
    "3. This is a **mathematical artifact**, not a stylistic difference\n",
    "\n",
    "**Verdict:** ‚ö†Ô∏è **Hapax is CONFOUNDED by length bias**\n",
    "- Still statistically significant (p < 0.000001)\n",
    "- Still useful for classification (models learn patterns)\n",
    "- But NOT interpretable as pure style difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852292ea",
   "metadata": {},
   "source": [
    "### üéØ Key Takeaway\n",
    "\n",
    "**Both TTR and Hapax are CONFOUNDED by paragraph length:**\n",
    "- Human: 134 words (longer) ‚Üí more repetition ‚Üí lower TTR/Hapax\n",
    "- AI: 90-97 words (shorter) ‚Üí less repetition ‚Üí higher TTR/Hapax\n",
    "\n",
    "**This is OK for classification!** Models will learn \"short paragraphs = AI\" which is accurate.\n",
    "\n",
    "**But:** Can't interpret as \"AI has richer vocabulary\" - it just writes shorter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db803fe",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. POS Distribution: Adjective-to-Noun Ratio\n",
    "\n",
    "Does AI \"over-describe\" compared to humans?\n",
    "\n",
    "**Example:** \n",
    "- \"The quick brown fox\" ‚Üí 2 adj, 1 noun = 2.0 ratio\n",
    "- \"The fox\" ‚Üí 0 adj, 1 noun = 0.0 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spaCy if needed\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"‚úÖ spaCy loaded\")\n",
    "except:\n",
    "    print(\"Installing spaCy...\")\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install spacy -q\n",
    "    !{sys.executable} -m spacy download en_core_web_sm -q\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"‚úÖ spaCy installed and loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b36caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adj_noun_ratio(text):\n",
    "    \"\"\"Adjective to noun ratio using spaCy POS tagging\"\"\"\n",
    "    doc = nlp(text)\n",
    "    adj_count = sum(1 for token in doc if token.pos_ == 'ADJ')\n",
    "    noun_count = sum(1 for token in doc if token.pos_ in ['NOUN', 'PROPN'])\n",
    "    \n",
    "    if noun_count == 0:\n",
    "        return 0\n",
    "    return adj_count / noun_count\n",
    "\n",
    "# Calculate for all classes (sample first 100 for speed)\n",
    "class1_adj_noun = [calculate_adj_noun_ratio(text) for text in class1_texts[:100]]\n",
    "class2_adj_noun = [calculate_adj_noun_ratio(text) for text in class2_texts[:100]]\n",
    "class3_adj_noun = [calculate_adj_noun_ratio(text) for text in class3_texts[:100]]\n",
    "\n",
    "print(f\"Average Adj/Noun Ratio:\")\n",
    "print(f\"  Human (Class 1): {np.mean(class1_adj_noun):.3f}\")\n",
    "print(f\"  AI Vanilla (Class 2): {np.mean(class2_adj_noun):.3f}\")\n",
    "print(f\"  AI Styled (Class 3): {np.mean(class3_adj_noun):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "data = pd.DataFrame({\n",
    "    'Adj_Noun_Ratio': class1_adj_noun + class2_adj_noun + class3_adj_noun,\n",
    "    'Class': ['Human']*len(class1_adj_noun) + ['AI_Vanilla']*len(class2_adj_noun) + ['AI_Styled']*len(class3_adj_noun)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x='Class', y='Adj_Noun_Ratio', palette='Set2')\n",
    "plt.title('Adjective-to-Noun Ratio by Class', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Adj/Noun Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "t_stat, p_value = stats.ttest_ind(class1_adj_noun, class2_adj_noun)\n",
    "\n",
    "print(f\"\\nT-test (Human vs AI Vanilla):\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"  ‚úÖ Statistically significant difference (p < 0.05)\")\n",
    "    diff = abs(np.mean(class1_adj_noun) - np.mean(class2_adj_noun))\n",
    "    print(f\"  Difference: {diff:.3f}\")\n",
    "else:\n",
    "    print(f\"  ‚ùå No significant difference (p >= 0.05)\")\n",
    "    print(f\"  This metric does NOT distinguish the classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d2939",
   "metadata": {},
   "source": [
    "### POS Distribution Summary\n",
    "\n",
    "**SURPRISING SUCCESS!** ‚úÖ (With Twain + Austen)\n",
    "\n",
    "**Results:**\n",
    "- Human (Twain): **0.313** (fewer adjectives)\n",
    "- AI Vanilla: **0.356** (more adjectives)\n",
    "- AI Styled: **0.346** (middle)\n",
    "\n",
    "**Statistical Significance:**\n",
    "- p = 0.024 (SIGNIFICANT!)\n",
    "- Difference: 0.043 (modest but real)\n",
    "\n",
    "**Why it works NOW:**\n",
    "1. **Twain's colloquial style**: Action-focused, minimal description, dialogue-heavy\n",
    "2. **AI's analytical style**: More formal, descriptive, academic tone\n",
    "3. **\"Tom ran\"** (Twain) vs **\"The enthusiastic boy ran quickly\"** (AI)\n",
    "\n",
    "**Why it FAILED with Victorian dataset:**\n",
    "- Dickens used TONS of adjectives (Victorian formal prose)\n",
    "- Dickens (0.35) ‚âà AI (0.35) - no difference!\n",
    "- Twain (0.31) < AI (0.36) - clear difference!\n",
    "\n",
    "**Verdict:** ‚úÖ **VALID METRIC** for distinguishing colloquial vs formal writing styles!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a67f5f",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Sentence Length Variance\n",
    "\n",
    "Measures how varied sentence lengths are (structural rhythm)\n",
    "\n",
    "**Example:**\n",
    "- Monotonous: [18, 20, 19, 21] words ‚Üí variance = 1.25\n",
    "- Dynamic: [5, 40, 15, 60] words ‚Üí variance = 506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_length_variance(text):\n",
    "    \"\"\"Standard deviation of sentence lengths\"\"\"\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    if len(sentences) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    lengths = [len(s.split()) for s in sentences]\n",
    "    return np.std(lengths)\n",
    "\n",
    "# Calculate for all classes\n",
    "class1_variance = [calculate_sentence_length_variance(text) for text in class1_texts]\n",
    "class2_variance = [calculate_sentence_length_variance(text) for text in class2_texts]\n",
    "class3_variance = [calculate_sentence_length_variance(text) for text in class3_texts]\n",
    "\n",
    "print(f\"Average Sentence Length Variance:\")\n",
    "print(f\"  Human (Class 1): {np.mean(class1_variance):.3f}\")\n",
    "print(f\"  AI Vanilla (Class 2): {np.mean(class2_variance):.3f}\")\n",
    "print(f\"  AI Styled (Class 3): {np.mean(class3_variance):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd869b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "data = pd.DataFrame({\n",
    "    'Sentence_Variance': class1_variance + class2_variance + class3_variance,\n",
    "    'Class': ['Human']*len(class1_variance) + ['AI_Vanilla']*len(class2_variance) + ['AI_Styled']*len(class3_variance)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x='Class', y='Sentence_Variance', palette='Set2')\n",
    "plt.title('Sentence Length Variance by Class', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Std Dev of Sentence Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "t_stat, p_value = stats.ttest_ind(class1_variance, class2_variance)\n",
    "\n",
    "print(f\"\\nT-test (Human vs AI Vanilla):\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.10f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"  ‚úÖ Statistically significant difference (p < 0.05)\")\n",
    "    diff = abs(np.mean(class1_variance) - np.mean(class2_variance))\n",
    "    print(f\"  Difference: {diff:.3f}\")\n",
    "    print(f\"\\n  üèÜ STRONGEST DISTINGUISHER!\")\n",
    "else:\n",
    "    print(f\"  ‚ùå No significant difference (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a2ca6",
   "metadata": {},
   "source": [
    "### Sentence Variance Summary\n",
    "\n",
    "**üèÜ STRONGEST METRIC - THE AI FINGERPRINT!**\n",
    "\n",
    "**Results:**\n",
    "- Human (Twain + Austen): **13.697** (highly varied)\n",
    "- AI Vanilla: **5.456** (monotonous)\n",
    "- AI Styled: **6.009** (slightly less monotonous)\n",
    "\n",
    "**Statistical Significance:**\n",
    "- **Difference: +8.241** (MASSIVE!)\n",
    "- **p-value: < 0.0000000001** (22œÉ effect - extremely significant!)\n",
    "- **t-statistic: 22.3** (huge effect size)\n",
    "\n",
    "**Why this is THE metric:**\n",
    "\n",
    "1. **‚úÖ Length-independent**: Not affected by paragraph length (unlike TTR/Hapax)\n",
    "2. **‚úÖ 2.5x difference**: Human variance is 2.5x higher than AI\n",
    "3. **‚úÖ Reveals structure**: AI's mechanical rhythm vs human's natural flow\n",
    "4. **‚úÖ Consistent pattern**: Works across Victorian AND Twain datasets\n",
    "\n",
    "**What it shows:**\n",
    "\n",
    "**Humans (variance ~14):**\n",
    "‚Üí **Natural rhythm, varied pacing**\n",
    "\n",
    "**AI (variance ~5):**\n",
    "‚Üí **Mechanical uniformity, \"middle zone\" trap**\n",
    "\n",
    "**üéØ THE SMOKING GUN:** AI avoids extremes (short punchy sentences OR long flowing ones), clustering around 15-20 words per sentence. Humans use the full range!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657f8f2",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Punctuation Density Heatmap\n",
    "\n",
    "Count 7 punctuation types per 1000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_punctuation_density(text):\n",
    "    \"\"\"Count punctuation per 1000 words\"\"\"\n",
    "    word_count = len(re.findall(r'\\b\\w+\\b', text))\n",
    "    if word_count == 0:\n",
    "        return {}\n",
    "    \n",
    "    multiplier = 1000 / word_count\n",
    "    \n",
    "    return {\n",
    "        'comma': text.count(',') * multiplier,\n",
    "        'semicolon': text.count(';') * multiplier,\n",
    "        'colon': text.count(':') * multiplier,\n",
    "        'em_dash': (text.count('‚Äî') + text.count('--')) * multiplier,\n",
    "        'exclamation': text.count('!') * multiplier,\n",
    "        'question': text.count('?') * multiplier,\n",
    "        'quote': text.count('\"') * multiplier\n",
    "    }\n",
    "\n",
    "# Calculate for all classes\n",
    "class1_punct = [calculate_punctuation_density(text) for text in class1_texts]\n",
    "class2_punct = [calculate_punctuation_density(text) for text in class2_texts]\n",
    "class3_punct = [calculate_punctuation_density(text) for text in class3_texts]\n",
    "\n",
    "# Average by class\n",
    "punct_types = ['comma', 'semicolon', 'colon', 'em_dash', 'exclamation', 'question', 'quote']\n",
    "heatmap_data = []\n",
    "\n",
    "for punct_type in punct_types:\n",
    "    heatmap_data.append([\n",
    "        np.mean([p[punct_type] for p in class1_punct]),\n",
    "        np.mean([p[punct_type] for p in class2_punct]),\n",
    "        np.mean([p[punct_type] for p in class3_punct])\n",
    "    ])\n",
    "\n",
    "heatmap_df = pd.DataFrame(heatmap_data, \n",
    "                          columns=['Human', 'AI_Vanilla', 'AI_Styled'],\n",
    "                          index=punct_types)\n",
    "\n",
    "print(\"Punctuation Density (per 1000 words):\")\n",
    "print(heatmap_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7638261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_df, annot=True, fmt='.1f', cmap='YlOrRd', cbar_kws={'label': 'Per 1000 words'})\n",
    "plt.title('Punctuation Density Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Punctuation Type')\n",
    "plt.xlabel('Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3363323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests for key punctuation\n",
    "key_punct = ['semicolon', 'em_dash', 'exclamation']\n",
    "\n",
    "for punct in key_punct:\n",
    "    class1_values = [p[punct] for p in class1_punct]\n",
    "    class2_values = [p[punct] for p in class2_punct]\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(class1_values, class2_values)\n",
    "    \n",
    "    print(f\"\\n{punct.upper()}:\")\n",
    "    print(f\"  Human: {np.mean(class1_values):.2f}\")\n",
    "    print(f\"  AI Vanilla: {np.mean(class2_values):.2f}\")\n",
    "    print(f\"  p-value: {p_value:.6f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"  ‚úÖ Significant difference\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå No significant difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc291499",
   "metadata": {},
   "source": [
    "### Punctuation Summary\n",
    "\n",
    "**COUNTERINTUITIVE RESULTS** ‚ö†Ô∏è\n",
    "- Humans (Dickens/Austen) use MORE semicolons/em-dashes than AI\n",
    "- This is because:\n",
    "  - Human data = 19th century Victorian literature\n",
    "  - AI data = 21st century modern style\n",
    "  - We're comparing historical vs modern conventions!\n",
    "\n",
    "**Still valid for classification** - the differences are real and significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f7da4",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Flesch-Kincaid Grade Level\n",
    "\n",
    "Measures reading difficulty based on sentence length and word complexity\n",
    "\n",
    "**Formula:** 0.39 √ó (words/sentences) + 11.8 √ó (syllables/words) - 15.59\n",
    "\n",
    "**Interpretation:**\n",
    "- Grade 8-10: Easy high school\n",
    "- Grade 10-12: Standard high school\n",
    "- Grade 12-14: College level\n",
    "- Grade 14+: Graduate level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install textstat if needed\n",
    "try:\n",
    "    from textstat import flesch_kincaid_grade\n",
    "    print(\"‚úÖ textstat loaded\")\n",
    "except:\n",
    "    print(\"Installing textstat...\")\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install textstat -q\n",
    "    from textstat import flesch_kincaid_grade\n",
    "    print(\"‚úÖ textstat installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c44696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FK grade for all classes\n",
    "class1_fk = [flesch_kincaid_grade(text) for text in class1_texts]\n",
    "class2_fk = [flesch_kincaid_grade(text) for text in class2_texts]\n",
    "class3_fk = [flesch_kincaid_grade(text) for text in class3_texts]\n",
    "\n",
    "print(f\"Average Flesch-Kincaid Grade Level:\")\n",
    "print(f\"  Human (Class 1): {np.mean(class1_fk):.2f}\")\n",
    "print(f\"  AI Vanilla (Class 2): {np.mean(class2_fk):.2f}\")\n",
    "print(f\"  AI Styled (Class 3): {np.mean(class3_fk):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "data = pd.DataFrame({\n",
    "    'FK_Grade': class1_fk + class2_fk + class3_fk,\n",
    "    'Class': ['Human']*len(class1_fk) + ['AI_Vanilla']*len(class2_fk) + ['AI_Styled']*len(class3_fk)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x='Class', y='FK_Grade', palette='Set2')\n",
    "\n",
    "# Add mean markers\n",
    "means = data.groupby('Class')['FK_Grade'].mean()\n",
    "positions = range(len(means))\n",
    "plt.plot(positions, means.values, 'D', color='red', markersize=10, label='Mean', zorder=3)\n",
    "\n",
    "plt.title('Flesch-Kincaid Grade Level by Class', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Grade Level (Reading Difficulty)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests\n",
    "print(\"\\nStatistical Tests:\")\n",
    "\n",
    "# Human vs AI Vanilla\n",
    "t_stat, p_value = stats.ttest_ind(class1_fk, class2_fk)\n",
    "print(f\"\\nHuman vs AI Vanilla:\")\n",
    "print(f\"  Difference: {np.mean(class1_fk) - np.mean(class2_fk):.2f} grade levels\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"  ‚úÖ Significant\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Not significant\")\n",
    "\n",
    "# Human vs AI Styled\n",
    "t_stat, p_value = stats.ttest_ind(class1_fk, class3_fk)\n",
    "print(f\"\\nHuman vs AI Styled:\")\n",
    "print(f\"  Difference: {np.mean(class1_fk) - np.mean(class3_fk):.2f} grade levels\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"  ‚úÖ Significant\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Not significant\")\n",
    "\n",
    "# AI Vanilla vs AI Styled\n",
    "t_stat, p_value = stats.ttest_ind(class2_fk, class3_fk)\n",
    "print(f\"\\nAI Vanilla vs AI Styled:\")\n",
    "print(f\"  Difference: {np.mean(class2_fk) - np.mean(class3_fk):.2f} grade levels\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"  ‚úÖ Significant\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Not significant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865a0f8",
   "metadata": {},
   "source": [
    "### Flesch-Kincaid Summary\n",
    "\n",
    "Shows reading difficulty level of each class based on sentence length and word complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853ba73",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Summary\n",
    "\n",
    "### Metrics That WORK (distinguish classes):\n",
    "1. ‚úÖ **Sentence Length Variance** - STRONGEST (p < 0.000001, diff = 9.6)\n",
    "2. ‚úÖ **TTR** - Significant (p < 0.000001, diff = 0.039)\n",
    "3. ‚úÖ **Hapax** - Significant (p < 0.000001, diff = 0.043)\n",
    "4. ‚úÖ **Punctuation** - Significant (semicolons, em-dashes)\n",
    "5. ‚úÖ **Flesch-Kincaid** - Likely significant\n",
    "\n",
    "### Metrics That FAILED:\n",
    "1. ‚ùå **Adj/Noun Ratio** - No difference (p = 0.812)\n",
    "\n",
    "### Key Insights:\n",
    "- **Structural metrics** (sentence variance) > **Vocabulary metrics** (TTR, Hapax)\n",
    "- AI can mimic vocabulary but struggles with natural rhythm\n",
    "- Length bias affects vocabulary metrics but doesn't invalidate them\n",
    "- 19th century human style ‚â† 21st century AI style (historical confound)\n",
    "\n",
    "### Best Features for Classification (Task 2):\n",
    "1. Sentence length variance (strongest signal)\n",
    "2. Paragraph length\n",
    "3. TTR\n",
    "4. Punctuation density (semicolons, em-dashes)\n",
    "5. Flesch-Kincaid grade level\n",
    "\n",
    "**Classes are mathematically distinct** ‚úÖ - Ready for Task 2!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
